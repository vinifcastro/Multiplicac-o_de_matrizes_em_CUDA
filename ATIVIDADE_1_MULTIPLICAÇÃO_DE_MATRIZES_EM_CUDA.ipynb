{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_WHrq0dqRo2D",
        "6hLsXCnyRxTS",
        "3iLBNkQJSi3r"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHIOUP+gI+HpL1Xp0Dzk8v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ATIVIDADE 1 - MULTIPLICAÇÃO DE MATRIZES EM CUDA"
      ],
      "metadata": {
        "id": "eHTYg2nGS3FL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INSTALANDO O PYCUDA\n"
      ],
      "metadata": {
        "id": "_WHrq0dqRo2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRCzRrXkRC4o",
        "outputId": "a64b9888-a437-4f0e-caaf-909bee963bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Downloading pytools-2025.1.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660425 sha256=d50f5a2a4b92f6729ab8e9114f9dd19c600575ed2a280ba5a78e5578ab595ebc\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, pycuda\n",
            "Successfully installed pycuda-2025.1 pytools-2025.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importações e geração das matrizes"
      ],
      "metadata": {
        "id": "6hLsXCnyRxTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "\n",
        "# Dimensões da matriz\n",
        "M, K, N = 512, 512, 512\n",
        "\n",
        "# Matrizes de entrada e saída\n",
        "A = np.random.randint(0, 10, (M, K)).astype(np.int32)\n",
        "B = np.random.randint(0, 10, (K, N)).astype(np.int32)\n",
        "C = np.zeros((M, N), dtype=np.int32)\n"
      ],
      "metadata": {
        "id": "ZNIdYVtWRoGs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRINT DAS MATRIZES GERADAS"
      ],
      "metadata": {
        "id": "3iLBNkQJSi3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz A:\")\n",
        "print(A)\n",
        "\n",
        "print(\"\\nMatriz B:\")\n",
        "print(B)\n",
        "\n",
        "print(\"\\nResultado da multiplicação na GPU (Matriz C):\")\n",
        "print(C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZEIFSwuSmLl",
        "outputId": "9b9ec71e-b2c5-4429-b181-415a0464b79c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz A:\n",
            "[[3 0 4 ... 1 1 9]\n",
            " [5 6 6 ... 7 3 3]\n",
            " [7 0 0 ... 1 2 8]\n",
            " ...\n",
            " [4 2 3 ... 5 2 8]\n",
            " [9 2 4 ... 2 8 4]\n",
            " [0 8 5 ... 1 9 1]]\n",
            "\n",
            "Matriz B:\n",
            "[[6 4 0 ... 6 1 3]\n",
            " [5 7 3 ... 6 5 4]\n",
            " [3 5 5 ... 7 5 9]\n",
            " ...\n",
            " [8 4 5 ... 0 5 8]\n",
            " [9 0 5 ... 4 3 8]\n",
            " [6 2 5 ... 1 8 0]]\n",
            "\n",
            "Resultado da multiplicação na GPU (Matriz C):\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MULTIPLICAÇÃO NA CPU USANDO NUMPY"
      ],
      "metadata": {
        "id": "R69X9eYoSopE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time_cpu = time.time()\n",
        "C_cpu = np.dot(A, B)\n",
        "end_time_cpu = time.time()\n",
        "\n",
        "print(f\"Tempo de execução na CPU: {end_time_cpu - start_time_cpu:.6f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GISjfCB3SwQ8",
        "outputId": "a2b14e3d-4fe2-49a3-e8af-b1815382e44d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução na CPU: 0.244950 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definindo bloco e kernel CUDA com PyCUDA"
      ],
      "metadata": {
        "id": "CNkRAZIzTaq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 16\n",
        "\n",
        "kernel_code = \"\"\"\n",
        "__global__ void MatrixMulKernel(int *A, int *B, int *C, int M, int N, int K) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < M && col < N) {\n",
        "        int temp = 0;\n",
        "        for (int i = 0; i < K; ++i) {\n",
        "            temp += A[row * K + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = temp;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "D5MKpNKTTfFr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilação do kernel e alocação na GPU"
      ],
      "metadata": {
        "id": "RIkP9AqxTotl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(kernel_code)\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "# Alocação de memória e cópia dos dados para GPU\n",
        "A_gpu = cuda.mem_alloc(A.nbytes)\n",
        "B_gpu = cuda.mem_alloc(B.nbytes)\n",
        "C_gpu = cuda.mem_alloc(C.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(A_gpu, A)\n",
        "cuda.memcpy_htod(B_gpu, B)\n"
      ],
      "metadata": {
        "id": "p7OPqu0PTvq1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execução na GPU"
      ],
      "metadata": {
        "id": "1etXginTTy0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = ((N + BLOCK_SIZE - 1) // BLOCK_SIZE, (M + BLOCK_SIZE - 1) // BLOCK_SIZE)\n",
        "block = (BLOCK_SIZE, BLOCK_SIZE, 1)\n",
        "\n",
        "start_time_gpu_16 = time.time()\n",
        "matrixmul(A_gpu, B_gpu, C_gpu, np.int32(M), np.int32(N), np.int32(K), block=block, grid=grid)\n",
        "cuda.memcpy_dtoh(C, C_gpu)\n",
        "end_time_gpu_16 = time.time()\n",
        "\n",
        "print(f\"Tempo de execução na GPU: {end_time_gpu - start_time_gpu:.6f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDAPqhU6T05B",
        "outputId": "f3050ca9-d4c8-4773-9c3d-1b5e00054ae0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução na GPU: 0.001866 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COMPARAÇÃO DOS RESULTADOS ENTRE CPU E BLOCO DE TAMANHO 16"
      ],
      "metadata": {
        "id": "VAEcjOSEWIYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if np.allclose(C, C_cpu):\n",
        "    print(\"Resultado CORRETO (GPU == CPU)\")\n",
        "else:\n",
        "    print(\"Resultado INCORRETO (diferença entre GPU e CPU)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORHjShQqWKrj",
        "outputId": "17895cb2-196a-4517-e131-6f301d75f679"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado CORRETO (GPU == CPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparação dos tempos"
      ],
      "metadata": {
        "id": "zkpl3Q_FUQMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempo_cpu = end_time_cpu - start_time_cpu\n",
        "tempo_gpu_16 = end_time_gpu_16 - start_time_gpu_16\n",
        "\n",
        "print(\"\\n====== COMPARAÇÃO DE DESEMPENHO ======\")\n",
        "if tempo_cpu < tempo_gpu_16:\n",
        "    print(f\"A CPU foi mais rápida por {tempo_gpu_16 - tempo_cpu:.6f} segundos.\")\n",
        "else:\n",
        "    print(f\"A GPU foi mais rápida por {tempo_cpu - tempo_gpu_16:.6f} segundos.\")\n",
        "\n",
        "print(f\"\\nTempo CPU: {tempo_gpu_16:.6f} segundos\")\n",
        "print(f\"Tempo GPU: {tempo_gpu_16:.6f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s00W2wLmUTDj",
        "outputId": "846e9b85-1ff8-4ab0-a01e-64558e798f4e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== COMPARAÇÃO DE DESEMPENHO ======\n",
            "A GPU foi mais rápida por 0.243045 segundos.\n",
            "\n",
            "Tempo CPU: 0.001905 segundos\n",
            "Tempo GPU: 0.001905 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PARA BLOCO DE TAMANHO 32"
      ],
      "metadata": {
        "id": "fHULIblTVHPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 32  # novo tamanho de bloco\n",
        "\n",
        "# Recalcula grid e block\n",
        "block = (BLOCK_SIZE, BLOCK_SIZE, 1)\n",
        "grid = ((N + BLOCK_SIZE - 1) // BLOCK_SIZE, (M + BLOCK_SIZE - 1) // BLOCK_SIZE)\n",
        "\n",
        "start_time_gpu_32 = time.time()\n",
        "matrixmul(A_gpu, B_gpu, C_gpu, np.int32(M), np.int32(N), np.int32(K), block=block, grid=grid)\n",
        "cuda.memcpy_dtoh(C, C_gpu)\n",
        "end_time_gpu_32 = time.time()\n",
        "\n",
        "print(f\"GPU com BLOCK_SIZE=32: {end_time_gpu_32 - start_time_gpu_32:.6f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6_hnBYgVLc1",
        "outputId": "2b32265b-f7de-4458-d6ec-4b40b2a04487"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU com BLOCK_SIZE=32: 0.001577 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COMPARAÇÃO DOS RESULTADOS ENTRE CPU E BLOCO DE TAMANHO 32"
      ],
      "metadata": {
        "id": "3-I9L23RWZjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if np.allclose(C, C_cpu):\n",
        "    print(\"Resultado CORRETO (GPU == CPU)\")\n",
        "else:\n",
        "    print(\"Resultado INCORRETO (diferença entre GPU e CPU)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbRLsjokWT-h",
        "outputId": "224b1d1a-88c5-464d-c10b-9b21818d36b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado CORRETO (GPU == CPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COMPARAÇÃO DE TEMPO ENTRE BLOCO DE 32 E 16"
      ],
      "metadata": {
        "id": "eYSlqcYfVaOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempo_gpu_16 = end_time_gpu_16 - start_time_gpu_16\n",
        "tempo_gpu_32 = end_time_gpu_32 - start_time_gpu_32\n",
        "\n",
        "print(\"\\n====== COMPARAÇÃO ENTRE BLOCK_SIZES ======\")\n",
        "if tempo_gpu_16 < tempo_gpu_32:\n",
        "    print(f\"BLOCO 16x16 foi mais rápido por {tempo_gpu_32 - tempo_gpu_16:.6f} segundos\")\n",
        "else:\n",
        "    print(f\"BLOCO 32x32 foi mais rápido por {tempo_gpu_16 - tempo_gpu_32:.6f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ouP01LeVe8v",
        "outputId": "4241925d-e857-4d4b-c8e8-759ddf16555c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== COMPARAÇÃO ENTRE BLOCK_SIZES ======\n",
            "BLOCO 32x32 foi mais rápido por 0.000328 segundos\n"
          ]
        }
      ]
    }
  ]
}